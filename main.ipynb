{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16fe55b7-5a4a-4642-9089-074b5ecf9118",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"main.env\")  # Make sure you have GOOGLE_API_KEY in this file\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13b2539a-6a1c-4281-aa9c-4fbf4cd3195d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28b64899-28b1-4840-b75d-93698852cabf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: llama-index\n",
      "Version: 0.12.44\n",
      "Summary: Interface between LLMs and your data\n",
      "Home-page: https://llamaindex.ai\n",
      "Author: \n",
      "Author-email: Jerry Liu <jerry@llamaindex.ai>\n",
      "License-Expression: MIT\n",
      "Location: /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages\n",
      "Requires: llama-index-agent-openai, llama-index-cli, llama-index-core, llama-index-embeddings-openai, llama-index-indices-managed-llama-cloud, llama-index-llms-openai, llama-index-multi-modal-llms-openai, llama-index-program-openai, llama-index-question-gen-openai, llama-index-readers-file, llama-index-readers-llama-parse, nltk\n",
      "Required-by: llama-hub\n"
     ]
    }
   ],
   "source": [
    "!pip show llama-index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efeacea1-feec-490d-bb5b-7a0c373c8d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:'doc_id' is deprecated and 'id_' will be used instead\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from llama_index.readers.file import UnstructuredReader\n",
    "\n",
    "reader = UnstructuredReader()\n",
    "docs = reader.load_data(Path(\"docs/story.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb6764ae-ff6d-400d-9c8f-625505c9fcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting into chuks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e52cad4-2d1a-4ffb-a7ca-b54495ce1360",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "\n",
    "splitter = SentenceSplitter(\n",
    "    chunk_size=384,         # balances granularity and context\n",
    "    chunk_overlap=64,       # ensures smooth transitions\n",
    "    paragraph_separator=\"\\n\\n\"  # ideal for narrative/story formatting\n",
    ")\n",
    "\n",
    "nodes = splitter.get_nodes_from_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56a8b179-c329-4f26-b67c-6ea7a43b1cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Chunk 1 ---\n",
      "Title: The Shadows of Arinvale\n",
      "\n",
      "Prologue: Legends whispered of a city beneath the roots of the world — Arinvale. Few believed it. Fewer returned. But in the year 1421, strange lights began dancing across the Northern Forests, and the whispers turned into fearful prayers.\n",
      "\n",
      "Chapter 1: The Letter Arin Windthorn, a scribe's apprentice in the coastal town of Evermist, receives a sealed letter with no name. Inside: a single sentence — \"The truth sleeps beneath your name.\" Haunted by dreams of a sunken\n",
      "\n",
      "--- Chunk 2 ---\n",
      "Chapter 4: The Storm Ritual As storms begin to ravage the region, Nara performs the forgotten Rite of Echoes. In the heart of the tempest, Arin sees visions: his childhood rewritten, a burning village, and a sigil etched on his spine.\n",
      "\n",
      "Chapter 5: The Betrayal Elgar returns — but not as an ally. Revealed as a Watcher in disguise, he tries to bind Arin using blood magic. Nara sacrifices her essence to sever the link, shattering the last storm crystal.\n",
      "\n",
      "Chapter 6: The Descent Now marked and hunted,\n",
      "\n",
      "--- Chunk 3 ---\n",
      "Epilogue: A century later, children in Evermist speak of a voice in dreams guiding lost wanderers through the forest. They call it the Shadow Shepherd — once a boy named Arin Windthorn.\n",
      "\n",
      "Characters: - **Arin Windthorn**: Protagonist, young and curious, heir to a secret bloodline. - **Nara**: Blind keeper of the Hollow Library, speaks in riddles, later sacrifices herself. - **Elgar**: Mysterious hunter, later revealed as a Watcher and antagonist. - **The Watchers**: Hooded figures guarding the tr\n"
     ]
    }
   ],
   "source": [
    "for i, node in enumerate(nodes[:3]):\n",
    "    print(f\"\\n--- Chunk {i+1} ---\")\n",
    "    print(node.text[:500])  # preview up to 500 characters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62446e7d-6f57-4208-8d91-4ccf4422e70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating embeeding with gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37200726-f6d7-4e3e-9b32-00cc5e3b5290",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/tmp/ipykernel_6481/2563350930.py:3: DeprecationWarning: Call to deprecated class GeminiEmbedding. (Should use `llama-index-embeddings-google-genai` instead, using Google's latest unified SDK. See: https://docs.llamaindex.ai/en/stable/examples/embeddings/google_genai/)\n",
      "  embed_model = GeminiEmbedding(model=\"models/embedding-001\")\n"
     ]
    }
   ],
   "source": [
    "from llama_index.embeddings.gemini import GeminiEmbedding\n",
    "\n",
    "embed_model = GeminiEmbedding(model=\"models/embedding-001\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba7e8bfa-daff-4b1e-a87d-b38604244032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pinecone "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea97b330-df44-47dc-b77a-bcf8fd2ed685",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6481/2599069295.py:7: DeprecationWarning: Call to deprecated class GeminiEmbedding. (Should use `llama-index-embeddings-google-genai` instead, using Google's latest unified SDK. See: https://docs.llamaindex.ai/en/stable/examples/embeddings/google_genai/)\n",
      "  embed_model = GeminiEmbedding(model=\"models/embedding-001\")\n",
      "Upserted vectors: 100%|███████████████████████████| 1/1 [00:01<00:00,  1.65s/it]\n"
     ]
    }
   ],
   "source": [
    "from llama_index.embeddings.gemini import GeminiEmbedding\n",
    "from llama_index.vector_stores.pinecone import PineconeVectorStore\n",
    "from llama_index.core import VectorStoreIndex, StorageContext\n",
    "from pinecone import Pinecone\n",
    "\n",
    "# Define Gemini embedding model\n",
    "embed_model = GeminiEmbedding(model=\"models/embedding-001\")\n",
    "\n",
    "# Connect to Pinecone\n",
    "pc = Pinecone(api_key=os.getenv(\"PINECONE_API_KEY\"))\n",
    "pinecone_index = pc.Index(\"chatbot-index\")\n",
    "vector_store = PineconeVectorStore(pinecone_index=pinecone_index)\n",
    "\n",
    "# Storage context\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "# ✅ Build index (with embed_model explicitly passed)\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    docs,\n",
    "    storage_context=storage_context,\n",
    "    embed_model=embed_model\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c19678b-d0bf-416a-b001-074cce63ba27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.gemini import Gemini\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine  # ✅ from core\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "07b24957-1381-43c4-8072-49644ef1f245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index-llms-gemini in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (0.5.0)\n",
      "Requirement already satisfied: google-generativeai>=0.5.2 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from llama-index-llms-gemini) (0.8.5)\n",
      "Requirement already satisfied: llama-index-core<0.13,>=0.12.12 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from llama-index-llms-gemini) (0.12.44)\n",
      "Requirement already satisfied: pillow<11,>=10.2.0 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from llama-index-llms-gemini) (10.4.0)\n",
      "Requirement already satisfied: aiohttp<4,>=3.8.6 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (3.12.13)\n",
      "Requirement already satisfied: aiosqlite in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (0.21.0)\n",
      "Requirement already satisfied: banks<3,>=2.0.0 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (2.1.3)\n",
      "Requirement already satisfied: dataclasses-json in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (1.2.18)\n",
      "Requirement already satisfied: dirtyjson<2,>=1.0.8 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (1.0.8)\n",
      "Requirement already satisfied: filetype<2,>=1.2.0 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (2025.5.1)\n",
      "Requirement already satisfied: httpx in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (0.28.1)\n",
      "Requirement already satisfied: llama-index-workflows<2,>=1.0.1 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (1.0.1)\n",
      "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (3.4.2)\n",
      "Requirement already satisfied: nltk>3.8.1 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (3.9.1)\n",
      "Requirement already satisfied: numpy in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (2.2.6)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (2.11.7)\n",
      "Requirement already satisfied: pyyaml>=6.0.1 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (2.32.4)\n",
      "Requirement already satisfied: setuptools>=80.9.0 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (80.9.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.49 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (2.0.41)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (9.1.2)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (0.9.0)\n",
      "Requirement already satisfied: tqdm<5,>=4.66.1 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (1.17.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (1.20.1)\n",
      "Requirement already satisfied: griffe in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (1.7.3)\n",
      "Requirement already satisfied: jinja2 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (3.1.6)\n",
      "Requirement already satisfied: platformdirs in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (4.3.7)\n",
      "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from llama-index-workflows<2,>=1.0.1->llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (0.2.0)\n",
      "Requirement already satisfied: idna>=2.0 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from yarl<2.0,>=1.17.0->aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (3.7)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from google-generativeai>=0.5.2->llama-index-llms-gemini) (0.6.15)\n",
      "Requirement already satisfied: google-api-core in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from google-generativeai>=0.5.2->llama-index-llms-gemini) (2.25.1)\n",
      "Requirement already satisfied: google-api-python-client in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from google-generativeai>=0.5.2->llama-index-llms-gemini) (2.174.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from google-generativeai>=0.5.2->llama-index-llms-gemini) (2.40.3)\n",
      "Requirement already satisfied: protobuf in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from google-generativeai>=0.5.2->llama-index-llms-gemini) (5.29.5)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai>=0.5.2->llama-index-llms-gemini) (1.26.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from google-api-core->google-generativeai>=0.5.2->llama-index-llms-gemini) (1.70.0)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai>=0.5.2->llama-index-llms-gemini) (1.73.1)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai>=0.5.2->llama-index-llms-gemini) (1.71.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from google-auth>=2.15.0->google-generativeai>=0.5.2->llama-index-llms-gemini) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from google-auth>=2.15.0->google-generativeai>=0.5.2->llama-index-llms-gemini) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from google-auth>=2.15.0->google-generativeai>=0.5.2->llama-index-llms-gemini) (4.9.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (2025.6.15)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from rsa<5,>=3.1.4->google-auth>=2.15.0->google-generativeai>=0.5.2->llama-index-llms-gemini) (0.6.1)\n",
      "Requirement already satisfied: click in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from nltk>3.8.1->llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (8.1.8)\n",
      "Requirement already satisfied: joblib in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from nltk>3.8.1->llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (1.5.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from nltk>3.8.1->llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (2024.11.6)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (0.4.0)\n",
      "Requirement already satisfied: greenlet>=1 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (3.2.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (1.1.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from dataclasses-json->llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (3.26.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (24.2)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from google-api-python-client->google-generativeai>=0.5.2->llama-index-llms-gemini) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from google-api-python-client->google-generativeai>=0.5.2->llama-index-llms-gemini) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from google-api-python-client->google-generativeai>=0.5.2->llama-index-llms-gemini) (4.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai>=0.5.2->llama-index-llms-gemini) (3.2.3)\n",
      "Requirement already satisfied: colorama>=0.4 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from griffe->banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (0.4.6)\n",
      "Requirement already satisfied: anyio in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from httpx->llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (4.7.0)\n",
      "Requirement already satisfied: httpcore==1.* in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from httpx->llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from httpcore==1.*->httpx->llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (0.16.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from anyio->httpx->llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (1.2.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from anyio->httpx->llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from jinja2->banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index-llms-gemini\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d7aaedb-ac45-48cd-b8cf-2dda8c48b2d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6481/741215637.py:4: DeprecationWarning: Call to deprecated class Gemini. (Should use `llama-index-llms-google-genai` instead, using Google's latest unified SDK. See: https://docs.llamaindex.ai/en/stable/examples/llm/google_genai/)\n",
      "  llm = Gemini(model=\"models/gemini-1.5-pro-latest\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elgar, the hunter Arin met earlier, reappears as a Watcher and attempts to use blood magic against Arin. Nara sacrifices herself to protect Arin, breaking the Watcher's hold and destroying the last storm crystal.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from llama_index.llms.gemini import Gemini\n",
    "\n",
    "# Step 1: Create Gemini LLM\n",
    "llm = Gemini(model=\"models/gemini-1.5-pro-latest\")\n",
    "\n",
    "# Step 2: Use the index's built-in query engine\n",
    "query_engine = index.as_query_engine(llm=llm)\n",
    "\n",
    "# Step 3: Ask a question\n",
    "response = query_engine.query(\"What happened in Chapter 5?\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7899e239-cca2-434a-9d40-3f5c0cd62856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nara is the blind keeper of the Hollow Library, known for her riddles and for sacrificing herself to protect Arin.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"Who is Nara?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22c25084-3e11-4ec4-b462-20135e423536",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
    "\n",
    "query_engine_tool = QueryEngineTool(\n",
    "    query_engine=query_engine,\n",
    "    metadata=ToolMetadata(\n",
    "        name=\"arinvale_story_query_engine\",\n",
    "        description=\"Useful for answering questions about characters, events, and themes in the Arinvale story.\",\n",
    "    ),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3a2ab87-6993-42bc-8492-b2ee11a33153",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages/llama_index/core/agent/react/base.py:154: DeprecationWarning: Call to deprecated class ReActAgent. (ReActAgent has been rewritten and replaced by llama_index.core.agent.workflow.ReActAgent.\n",
      "\n",
      "This implementation will be removed in a v0.13.0 and the new implementation will be promoted to the `from llama_index.core.agent import ReActAgent` path.\n",
      "\n",
      "See the docs for more information: https://docs.llamaindex.ai/en/stable/understanding/agent/)\n",
      "  return cls(\n",
      "/home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages/deprecated/classic.py:184: DeprecationWarning: Call to deprecated class AgentRunner. (AgentRunner has been deprecated and is not maintained.\n",
      "\n",
      "This implementation will be removed in a v0.13.0.\n",
      "\n",
      "See the docs for more information on updated agent usage: https://docs.llamaindex.ai/en/stable/understanding/agent/)\n",
      "  return old_new1(cls, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The main themes of the Arinvale story are identity and legacy, the power of memory, the cost of truth, and the interplay between magic and technology.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.agent import ReActAgent\n",
    "\n",
    "agent = ReActAgent.from_tools([query_engine_tool], llm=llm)\n",
    "\n",
    "response = agent.query(\"What is the main theme of the story?\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9cb5ff24-91e7-4e22-809b-0208532a1e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💬 Arinvale Chatbot is ready! (type 'exit' to quit)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  who is nara?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: Nara is the blind keeper of the Hollow Library, who speaks in riddles and ultimately sacrifices herself.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  what is supervised learning?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: This query cannot be answered from the provided text, which describes the plot, characters, and setting of a fantasy novel.  There is no information about supervised learning.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "👋 Goodbye!\n"
     ]
    }
   ],
   "source": [
    "print(\"💬 Arinvale Chatbot is ready! (type 'exit' to quit)\\n\")\n",
    "\n",
    "while True:\n",
    "    query = input(\"You: \")\n",
    "    if query.strip().lower() in {\"exit\", \"quit\"}:\n",
    "        print(\"👋 Goodbye!\")\n",
    "        break\n",
    "\n",
    "    try:\n",
    "        response = query_engine.query(query)\n",
    "        print(f\"Bot: {response}\\n\")\n",
    "    except Exception as e:\n",
    "        print(\"⚠️ Error:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb51029-2a00-49d0-b49c-3de1ed884192",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
