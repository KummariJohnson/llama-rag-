{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16fe55b7-5a4a-4642-9089-074b5ecf9118",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"main.env\")  # Make sure you have GOOGLE_API_KEY in this file\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13b2539a-6a1c-4281-aa9c-4fbf4cd3195d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28b64899-28b1-4840-b75d-93698852cabf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: llama-index\n",
      "Version: 0.12.44\n",
      "Summary: Interface between LLMs and your data\n",
      "Home-page: https://llamaindex.ai\n",
      "Author: \n",
      "Author-email: Jerry Liu <jerry@llamaindex.ai>\n",
      "License-Expression: MIT\n",
      "Location: /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages\n",
      "Requires: llama-index-agent-openai, llama-index-cli, llama-index-core, llama-index-embeddings-openai, llama-index-indices-managed-llama-cloud, llama-index-llms-openai, llama-index-multi-modal-llms-openai, llama-index-program-openai, llama-index-question-gen-openai, llama-index-readers-file, llama-index-readers-llama-parse, nltk\n",
      "Required-by: llama-hub\n"
     ]
    }
   ],
   "source": [
    "!pip show llama-index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efeacea1-feec-490d-bb5b-7a0c373c8d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:'doc_id' is deprecated and 'id_' will be used instead\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from llama_index.readers.file import UnstructuredReader\n",
    "\n",
    "reader = UnstructuredReader()\n",
    "docs = reader.load_data(Path(\"docs/story.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb6764ae-ff6d-400d-9c8f-625505c9fcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting into chuks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e52cad4-2d1a-4ffb-a7ca-b54495ce1360",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "\n",
    "splitter = SentenceSplitter(\n",
    "    chunk_size=384,         # balances granularity and context\n",
    "    chunk_overlap=64,       # ensures smooth transitions\n",
    "    paragraph_separator=\"\\n\\n\"  # ideal for narrative/story formatting\n",
    ")\n",
    "\n",
    "nodes = splitter.get_nodes_from_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56a8b179-c329-4f26-b67c-6ea7a43b1cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Chunk 1 ---\n",
      "Title: The Shadows of Arinvale\n",
      "\n",
      "Prologue: Legends whispered of a city beneath the roots of the world ‚Äî Arinvale. Few believed it. Fewer returned. But in the year 1421, strange lights began dancing across the Northern Forests, and the whispers turned into fearful prayers.\n",
      "\n",
      "Chapter 1: The Letter Arin Windthorn, a scribe's apprentice in the coastal town of Evermist, receives a sealed letter with no name. Inside: a single sentence ‚Äî \"The truth sleeps beneath your name.\" Haunted by dreams of a sunken\n",
      "\n",
      "--- Chunk 2 ---\n",
      "Chapter 4: The Storm Ritual As storms begin to ravage the region, Nara performs the forgotten Rite of Echoes. In the heart of the tempest, Arin sees visions: his childhood rewritten, a burning village, and a sigil etched on his spine.\n",
      "\n",
      "Chapter 5: The Betrayal Elgar returns ‚Äî but not as an ally. Revealed as a Watcher in disguise, he tries to bind Arin using blood magic. Nara sacrifices her essence to sever the link, shattering the last storm crystal.\n",
      "\n",
      "Chapter 6: The Descent Now marked and hunted,\n",
      "\n",
      "--- Chunk 3 ---\n",
      "Epilogue: A century later, children in Evermist speak of a voice in dreams guiding lost wanderers through the forest. They call it the Shadow Shepherd ‚Äî once a boy named Arin Windthorn.\n",
      "\n",
      "Characters: - **Arin Windthorn**: Protagonist, young and curious, heir to a secret bloodline. - **Nara**: Blind keeper of the Hollow Library, speaks in riddles, later sacrifices herself. - **Elgar**: Mysterious hunter, later revealed as a Watcher and antagonist. - **The Watchers**: Hooded figures guarding the tr\n"
     ]
    }
   ],
   "source": [
    "for i, node in enumerate(nodes[:3]):\n",
    "    print(f\"\\n--- Chunk {i+1} ---\")\n",
    "    print(node.text[:500])  # preview up to 500 characters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62446e7d-6f57-4208-8d91-4ccf4422e70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating embeeding with gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37200726-f6d7-4e3e-9b32-00cc5e3b5290",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/tmp/ipykernel_6481/2563350930.py:3: DeprecationWarning: Call to deprecated class GeminiEmbedding. (Should use `llama-index-embeddings-google-genai` instead, using Google's latest unified SDK. See: https://docs.llamaindex.ai/en/stable/examples/embeddings/google_genai/)\n",
      "  embed_model = GeminiEmbedding(model=\"models/embedding-001\")\n"
     ]
    }
   ],
   "source": [
    "from llama_index.embeddings.gemini import GeminiEmbedding\n",
    "\n",
    "embed_model = GeminiEmbedding(model=\"models/embedding-001\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba7e8bfa-daff-4b1e-a87d-b38604244032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pinecone "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea97b330-df44-47dc-b77a-bcf8fd2ed685",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6481/2599069295.py:7: DeprecationWarning: Call to deprecated class GeminiEmbedding. (Should use `llama-index-embeddings-google-genai` instead, using Google's latest unified SDK. See: https://docs.llamaindex.ai/en/stable/examples/embeddings/google_genai/)\n",
      "  embed_model = GeminiEmbedding(model=\"models/embedding-001\")\n",
      "Upserted vectors: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.65s/it]\n"
     ]
    }
   ],
   "source": [
    "from llama_index.embeddings.gemini import GeminiEmbedding\n",
    "from llama_index.vector_stores.pinecone import PineconeVectorStore\n",
    "from llama_index.core import VectorStoreIndex, StorageContext\n",
    "from pinecone import Pinecone\n",
    "\n",
    "# Define Gemini embedding model\n",
    "embed_model = GeminiEmbedding(model=\"models/embedding-001\")\n",
    "\n",
    "# Connect to Pinecone\n",
    "pc = Pinecone(api_key=os.getenv(\"PINECONE_API_KEY\"))\n",
    "pinecone_index = pc.Index(\"chatbot-index\")\n",
    "vector_store = PineconeVectorStore(pinecone_index=pinecone_index)\n",
    "\n",
    "# Storage context\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "# ‚úÖ Build index (with embed_model explicitly passed)\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    docs,\n",
    "    storage_context=storage_context,\n",
    "    embed_model=embed_model\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c19678b-d0bf-416a-b001-074cce63ba27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.gemini import Gemini\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine  # ‚úÖ from core\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "07b24957-1381-43c4-8072-49644ef1f245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index-llms-gemini in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (0.5.0)\n",
      "Requirement already satisfied: google-generativeai>=0.5.2 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from llama-index-llms-gemini) (0.8.5)\n",
      "Requirement already satisfied: llama-index-core<0.13,>=0.12.12 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from llama-index-llms-gemini) (0.12.44)\n",
      "Requirement already satisfied: pillow<11,>=10.2.0 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from llama-index-llms-gemini) (10.4.0)\n",
      "Requirement already satisfied: aiohttp<4,>=3.8.6 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (3.12.13)\n",
      "Requirement already satisfied: aiosqlite in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (0.21.0)\n",
      "Requirement already satisfied: banks<3,>=2.0.0 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (2.1.3)\n",
      "Requirement already satisfied: dataclasses-json in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (1.2.18)\n",
      "Requirement already satisfied: dirtyjson<2,>=1.0.8 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (1.0.8)\n",
      "Requirement already satisfied: filetype<2,>=1.2.0 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (2025.5.1)\n",
      "Requirement already satisfied: httpx in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (0.28.1)\n",
      "Requirement already satisfied: llama-index-workflows<2,>=1.0.1 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (1.0.1)\n",
      "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (3.4.2)\n",
      "Requirement already satisfied: nltk>3.8.1 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (3.9.1)\n",
      "Requirement already satisfied: numpy in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (2.2.6)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (2.11.7)\n",
      "Requirement already satisfied: pyyaml>=6.0.1 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (2.32.4)\n",
      "Requirement already satisfied: setuptools>=80.9.0 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (80.9.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.49 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (2.0.41)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (9.1.2)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (0.9.0)\n",
      "Requirement already satisfied: tqdm<5,>=4.66.1 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (1.17.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (1.20.1)\n",
      "Requirement already satisfied: griffe in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (1.7.3)\n",
      "Requirement already satisfied: jinja2 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (3.1.6)\n",
      "Requirement already satisfied: platformdirs in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (4.3.7)\n",
      "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from llama-index-workflows<2,>=1.0.1->llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (0.2.0)\n",
      "Requirement already satisfied: idna>=2.0 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from yarl<2.0,>=1.17.0->aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (3.7)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from google-generativeai>=0.5.2->llama-index-llms-gemini) (0.6.15)\n",
      "Requirement already satisfied: google-api-core in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from google-generativeai>=0.5.2->llama-index-llms-gemini) (2.25.1)\n",
      "Requirement already satisfied: google-api-python-client in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from google-generativeai>=0.5.2->llama-index-llms-gemini) (2.174.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from google-generativeai>=0.5.2->llama-index-llms-gemini) (2.40.3)\n",
      "Requirement already satisfied: protobuf in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from google-generativeai>=0.5.2->llama-index-llms-gemini) (5.29.5)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai>=0.5.2->llama-index-llms-gemini) (1.26.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from google-api-core->google-generativeai>=0.5.2->llama-index-llms-gemini) (1.70.0)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai>=0.5.2->llama-index-llms-gemini) (1.73.1)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai>=0.5.2->llama-index-llms-gemini) (1.71.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from google-auth>=2.15.0->google-generativeai>=0.5.2->llama-index-llms-gemini) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from google-auth>=2.15.0->google-generativeai>=0.5.2->llama-index-llms-gemini) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from google-auth>=2.15.0->google-generativeai>=0.5.2->llama-index-llms-gemini) (4.9.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (2025.6.15)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from rsa<5,>=3.1.4->google-auth>=2.15.0->google-generativeai>=0.5.2->llama-index-llms-gemini) (0.6.1)\n",
      "Requirement already satisfied: click in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from nltk>3.8.1->llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (8.1.8)\n",
      "Requirement already satisfied: joblib in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from nltk>3.8.1->llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (1.5.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from nltk>3.8.1->llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (2024.11.6)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (0.4.0)\n",
      "Requirement already satisfied: greenlet>=1 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (3.2.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (1.1.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from dataclasses-json->llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (3.26.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (24.2)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from google-api-python-client->google-generativeai>=0.5.2->llama-index-llms-gemini) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from google-api-python-client->google-generativeai>=0.5.2->llama-index-llms-gemini) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from google-api-python-client->google-generativeai>=0.5.2->llama-index-llms-gemini) (4.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai>=0.5.2->llama-index-llms-gemini) (3.2.3)\n",
      "Requirement already satisfied: colorama>=0.4 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from griffe->banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (0.4.6)\n",
      "Requirement already satisfied: anyio in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from httpx->llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (4.7.0)\n",
      "Requirement already satisfied: httpcore==1.* in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from httpx->llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from httpcore==1.*->httpx->llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (0.16.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from anyio->httpx->llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (1.2.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from anyio->httpx->llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages (from jinja2->banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.12->llama-index-llms-gemini) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index-llms-gemini\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d7aaedb-ac45-48cd-b8cf-2dda8c48b2d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6481/741215637.py:4: DeprecationWarning: Call to deprecated class Gemini. (Should use `llama-index-llms-google-genai` instead, using Google's latest unified SDK. See: https://docs.llamaindex.ai/en/stable/examples/llm/google_genai/)\n",
      "  llm = Gemini(model=\"models/gemini-1.5-pro-latest\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elgar, the hunter Arin met earlier, reappears as a Watcher and attempts to use blood magic against Arin. Nara sacrifices herself to protect Arin, breaking the Watcher's hold and destroying the last storm crystal.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from llama_index.llms.gemini import Gemini\n",
    "\n",
    "# Step 1: Create Gemini LLM\n",
    "llm = Gemini(model=\"models/gemini-1.5-pro-latest\")\n",
    "\n",
    "# Step 2: Use the index's built-in query engine\n",
    "query_engine = index.as_query_engine(llm=llm)\n",
    "\n",
    "# Step 3: Ask a question\n",
    "response = query_engine.query(\"What happened in Chapter 5?\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7899e239-cca2-434a-9d40-3f5c0cd62856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nara is the blind keeper of the Hollow Library, known for her riddles and for sacrificing herself to protect Arin.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"Who is Nara?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22c25084-3e11-4ec4-b462-20135e423536",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
    "\n",
    "query_engine_tool = QueryEngineTool(\n",
    "    query_engine=query_engine,\n",
    "    metadata=ToolMetadata(\n",
    "        name=\"arinvale_story_query_engine\",\n",
    "        description=\"Useful for answering questions about characters, events, and themes in the Arinvale story.\",\n",
    "    ),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3a2ab87-6993-42bc-8492-b2ee11a33153",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages/llama_index/core/agent/react/base.py:154: DeprecationWarning: Call to deprecated class ReActAgent. (ReActAgent has been rewritten and replaced by llama_index.core.agent.workflow.ReActAgent.\n",
      "\n",
      "This implementation will be removed in a v0.13.0 and the new implementation will be promoted to the `from llama_index.core.agent import ReActAgent` path.\n",
      "\n",
      "See the docs for more information: https://docs.llamaindex.ai/en/stable/understanding/agent/)\n",
      "  return cls(\n",
      "/home/user/anaconda3/envs/llama_gemini/lib/python3.10/site-packages/deprecated/classic.py:184: DeprecationWarning: Call to deprecated class AgentRunner. (AgentRunner has been deprecated and is not maintained.\n",
      "\n",
      "This implementation will be removed in a v0.13.0.\n",
      "\n",
      "See the docs for more information on updated agent usage: https://docs.llamaindex.ai/en/stable/understanding/agent/)\n",
      "  return old_new1(cls, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The main themes of the Arinvale story are identity and legacy, the power of memory, the cost of truth, and the interplay between magic and technology.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.agent import ReActAgent\n",
    "\n",
    "agent = ReActAgent.from_tools([query_engine_tool], llm=llm)\n",
    "\n",
    "response = agent.query(\"What is the main theme of the story?\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9cb5ff24-91e7-4e22-809b-0208532a1e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí¨ Arinvale Chatbot is ready! (type 'exit' to quit)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  who is nara?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: Nara is the blind keeper of the Hollow Library, who speaks in riddles and ultimately sacrifices herself.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  what is supervised learning?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: This query cannot be answered from the provided text, which describes the plot, characters, and setting of a fantasy novel.  There is no information about supervised learning.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üëã Goodbye!\n"
     ]
    }
   ],
   "source": [
    "print(\"üí¨ Arinvale Chatbot is ready! (type 'exit' to quit)\\n\")\n",
    "\n",
    "while True:\n",
    "    query = input(\"You: \")\n",
    "    if query.strip().lower() in {\"exit\", \"quit\"}:\n",
    "        print(\"üëã Goodbye!\")\n",
    "        break\n",
    "\n",
    "    try:\n",
    "        response = query_engine.query(query)\n",
    "        print(f\"Bot: {response}\\n\")\n",
    "    except Exception as e:\n",
    "        print(\"‚ö†Ô∏è Error:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb51029-2a00-49d0-b49c-3de1ed884192",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
